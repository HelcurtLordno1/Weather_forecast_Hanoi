{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e0b748",
   "metadata": {},
   "source": [
    "# ğŸ“Š Comprehensive Model Training & Optimization Pipeline\n",
    "\n",
    "## ğŸ¯ Objective\n",
    "Build and optimize multiple machine learning models for **5-day ahead temperature forecasting** in Hanoi using comprehensive hyperparameter tuning.\n",
    "\n",
    "## ğŸ”§ Model Architecture\n",
    "This notebook implements a robust ML pipeline with:\n",
    "\n",
    "1. **Multiple ML Algorithms** - Random Forest, XGBoost, LightGBM, AdaBoost, Gradient Boosting\n",
    "2. **Hyperparameter Optimization** - Optuna Bayesian optimization with 50-100 trials per model\n",
    "3. **Time Series Validation** - Proper temporal splits to prevent data leakage\n",
    "4. **Performance Evaluation** - RMSE, MAE, RÂ², MAPE metrics\n",
    "5. **Model Selection** - Automated best model selection and deployment preparation\n",
    "\n",
    "## ğŸš€ ML Algorithms\n",
    "- **Random Forest**: Ensemble of decision trees with bootstrap aggregating\n",
    "- **XGBoost**: Gradient boosting with advanced regularization\n",
    "- **LightGBM**: Fast gradient boosting with leaf-wise tree growth\n",
    "- **AdaBoost**: Adaptive boosting with sequential weak learners\n",
    "- **Gradient Boosting**: Sequential gradient descent optimization\n",
    "\n",
    "## \udcc8 Key Features\n",
    "- **Temporal Integrity**: Time series splits prevent future data leakage\n",
    "- **Hyperparameter Tuning**: Optuna optimization for each algorithm\n",
    "- **Multi-Model Ensemble**: Compare tree-based approaches\n",
    "- **Feature Engineering**: 79 engineered features from weather data\n",
    "- **Deployment Ready**: Model persistence and metadata export\n",
    "\n",
    "## ğŸ¯ Expected Outcomes\n",
    "- Optimized models for 5-day temperature forecasting\n",
    "- Performance comparison across algorithms\n",
    "- Best model selection for deployment\n",
    "- Complete model package with metadata\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Implementation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3653a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ All libraries imported successfully!\n",
      "ğŸ”§ Models: Random Forest, XGBoost, LightGBM, AdaBoost, Gradient Boosting\n",
      "âš¡ Optimization: Optuna hyperparameter tuning\n",
      "ğŸ“Š Validation: Time series cross-validation\n",
      "ğŸ’¾ Persistence: Joblib model serialization\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Hyperparameter optimization\n",
    "import optuna\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append('..')\n",
    "from src.data_utils import load_hanoi_weather_data\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"ğŸ“¦ All libraries imported successfully!\")\n",
    "print(\"ğŸ”§ Models: Random Forest, XGBoost, LightGBM, AdaBoost, Gradient Boosting\")\n",
    "print(\"âš¡ Optimization: Optuna hyperparameter tuning\")\n",
    "print(\"ğŸ“Š Validation: Time series cross-validation\")\n",
    "print(\"ğŸ’¾ Persistence: Joblib model serialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf7f27c",
   "metadata": {},
   "source": [
    "### ğŸ“ Quick Setup Note:\n",
    "If you encounter an error about missing optuna package, run: `%pip install optuna` in a cell before the imports."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeedb747",
   "metadata": {},
   "source": [
    "## 1. Load Raw Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c3fe615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ WEATHER FORECASTING MODEL TRAINING PIPELINE\n",
      "============================================================\n",
      "ğŸ“Š Task: 5-day ahead temperature prediction\n",
      "ğŸ”§ Models: Random Forest, XGBoost, LightGBM, AdaBoost, Gradient Boosting\n",
      "âš¡ Optimization: Optuna Bayesian hyperparameter tuning\n",
      "ğŸ“ˆ Validation: Time series cross-validation\n",
      "ğŸ¯ Target: Minimize RMSE for temperature forecasting\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Project setup\n",
    "print(\"ğŸš€ WEATHER FORECASTING MODEL TRAINING PIPELINE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ“Š Task: 5-day ahead temperature prediction\")\n",
    "print(\"ğŸ”§ Models: Random Forest, XGBoost, LightGBM, AdaBoost, Gradient Boosting\")\n",
    "print(\"âš¡ Optimization: Optuna Bayesian hyperparameter tuning\")\n",
    "print(\"ğŸ“ˆ Validation: Time series cross-validation\")\n",
    "print(\"ğŸ¯ Target: Minimize RMSE for temperature forecasting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Configure Optuna to suppress verbose output\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe36a69",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Pipeline for Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5df5d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data_utils:Successfully loaded 3660 records from ../data/raw/Hanoi-Daily-10-years.csv\n",
      "INFO:src.data_utils:Date range: 2015-09-20 00:00:00 to 2025-09-26 00:00:00\n",
      "INFO:src.data_utils:Temperature range: 7.0Â°C to 35.5Â°C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded weather data: (3660, 33)\n",
      "ğŸ“… Date range: 2015-09-20 00:00:00 to 2025-09-26 00:00:00\n",
      "ğŸŒ¡ï¸ Temperature range: 7.0Â°C to 35.5Â°C\n",
      "ğŸ“Š Available features: ['name', 'datetime', 'tempmax', 'tempmin', 'temp', 'feelslikemax', 'feelslikemin', 'feelslike', 'dew', 'humidity', 'precip', 'precipprob', 'precipcover', 'preciptype', 'snow', 'snowdepth', 'windgust', 'windspeed', 'winddir', 'sealevelpressure', 'cloudcover', 'visibility', 'solarradiation', 'solarenergy', 'uvindex', 'severerisk', 'sunrise', 'sunset', 'moonphase', 'conditions', 'description', 'icon', 'stations']\n"
     ]
    }
   ],
   "source": [
    "# Load raw weather data\n",
    "data_path = '../data/raw/Hanoi-Daily-10-years.csv'  # Adjust path as needed\n",
    "\n",
    "try:\n",
    "    df_raw = load_hanoi_weather_data(data_path)\n",
    "    print(f\"âœ… Successfully loaded weather data: {df_raw.shape}\")\n",
    "    print(f\"ğŸ“… Date range: {df_raw['datetime'].min()} to {df_raw['datetime'].max()}\")\n",
    "    print(f\"ğŸŒ¡ï¸ Temperature range: {df_raw['temp'].min():.1f}Â°C to {df_raw['temp'].max():.1f}Â°C\")\n",
    "    print(f\"ğŸ“Š Available features: {list(df_raw.columns)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Data file not found. Please check the path:\")\n",
    "    print(f\"   Looking for: {data_path}\")\n",
    "    print(\"   Make sure the data file exists in the correct location.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7a5eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Creating forecasting features...\n",
      "ğŸ“Š Features created: (3660, 91)\n",
      "ğŸ¯ Target variable: temp_target (5-day ahead temperature)\n",
      "ğŸ“‹ Clean dataset: (737, 91) (after removing NaN from lags)\n"
     ]
    }
   ],
   "source": [
    "def create_forecasting_features(df, target_col='temp', forecast_horizon=5):\n",
    "    \"\"\"\n",
    "    Create comprehensive features for temperature forecasting\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort by datetime\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    # Temporal features\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek\n",
    "    df['dayofyear'] = df['datetime'].dt.dayofyear\n",
    "    df['quarter'] = df['datetime'].dt.quarter\n",
    "    \n",
    "    # Cyclical encoding\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    # Lag features for forecasting\n",
    "    for lag in [1, 2, 3, 5, 7, 14, 30]:\n",
    "        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)\n",
    "        \n",
    "    # Rolling statistics\n",
    "    for window in [3, 7, 14, 30]:\n",
    "        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window=window).mean()\n",
    "        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window=window).std()\n",
    "        df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(window=window).min()\n",
    "        df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(window=window).max()\n",
    "    \n",
    "    # Temperature differences\n",
    "    df['temp_diff_1d'] = df[target_col] - df[target_col].shift(1)\n",
    "    df['temp_diff_7d'] = df[target_col] - df[target_col].shift(7)\n",
    "    \n",
    "    # Weather feature lags (short-term)\n",
    "    weather_features = ['tempmax', 'tempmin', 'humidity', 'precip', 'windspeed']\n",
    "    for feature in weather_features:\n",
    "        if feature in df.columns:\n",
    "            for lag in [1, 2, 3]:\n",
    "                df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "    \n",
    "    # Create target variable (forecast_horizon days ahead)\n",
    "    df[f'{target_col}_target'] = df[target_col].shift(-forecast_horizon)\n",
    "    \n",
    "    # Season indicators\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]: return 'winter'\n",
    "        elif month in [3, 4, 5]: return 'spring'\n",
    "        elif month in [6, 7, 8]: return 'summer'\n",
    "        else: return 'autumn'\n",
    "    \n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    df['is_winter'] = (df['season'] == 'winter').astype(int)\n",
    "    df['is_spring'] = (df['season'] == 'spring').astype(int)\n",
    "    df['is_summer'] = (df['season'] == 'summer').astype(int)\n",
    "    df['is_autumn'] = (df['season'] == 'autumn').astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "print(\"ğŸ”§ Creating forecasting features...\")\n",
    "df_features = create_forecasting_features(df_raw, forecast_horizon=5)\n",
    "\n",
    "print(f\"ğŸ“Š Features created: {df_features.shape}\")\n",
    "print(f\"ğŸ¯ Target variable: temp_target (5-day ahead temperature)\")\n",
    "\n",
    "# Remove rows with NaN values (due to lags and target creation)\n",
    "df_clean = df_features.dropna().copy()\n",
    "print(f\"ğŸ“‹ Clean dataset: {df_clean.shape} (after removing NaN from lags)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8576fc",
   "metadata": {},
   "source": [
    "## 3. Feature Selection and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27c2b650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Selected 79 features for modeling:\n",
      "\n",
      "ğŸ“Š Feature categories:\n",
      "â€¢ Temporal features: 12\n",
      "â€¢ Lag features: 22\n",
      "â€¢ Rolling statistics: 16\n",
      "â€¢ Weather features: 29\n",
      "\n",
      "âœ… Training data prepared: X(737, 79), y(737,)\n",
      "ğŸ“… Training period: 2023-01-03 00:00:00 to 2025-09-21 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Define feature categories for modeling\n",
    "def select_modeling_features(df):\n",
    "    \"\"\"\n",
    "    Select relevant features for modeling, excluding non-predictive columns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Exclude non-predictive columns\n",
    "    exclude_cols = [\n",
    "        'datetime', 'name', 'stations', 'temp', 'temp_target',  # target and identifiers\n",
    "        'conditions', 'description', 'icon', 'preciptype', 'season',  # text/categorical\n",
    "        'sunrise', 'sunset'  # text time columns\n",
    "    ]\n",
    "    \n",
    "    # Select numerical features\n",
    "    feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "    \n",
    "    # Filter to ensure no remaining object/string columns\n",
    "    numerical_features = []\n",
    "    for col in feature_cols:\n",
    "        if df[col].dtype in ['int64', 'float64', 'int32', 'float32']:\n",
    "            numerical_features.append(col)\n",
    "    \n",
    "    return numerical_features\n",
    "\n",
    "# Select features\n",
    "feature_columns = select_modeling_features(df_clean)\n",
    "target_column = 'temp_target'\n",
    "\n",
    "print(f\"ğŸ¯ Selected {len(feature_columns)} features for modeling:\")\n",
    "print(\"\\nğŸ“Š Feature categories:\")\n",
    "\n",
    "# Categorize features for understanding\n",
    "temporal_features = [f for f in feature_columns if any(x in f for x in ['year', 'month', 'day', 'sin', 'cos', 'quarter', 'season'])]\n",
    "lag_features = [f for f in feature_columns if '_lag_' in f]\n",
    "rolling_features = [f for f in feature_columns if '_rolling_' in f]\n",
    "weather_features = [f for f in feature_columns if f not in temporal_features + lag_features + rolling_features]\n",
    "\n",
    "print(f\"â€¢ Temporal features: {len(temporal_features)}\")\n",
    "print(f\"â€¢ Lag features: {len(lag_features)}\")\n",
    "print(f\"â€¢ Rolling statistics: {len(rolling_features)}\")\n",
    "print(f\"â€¢ Weather features: {len(weather_features)}\")\n",
    "\n",
    "# Prepare training data\n",
    "X = df_clean[feature_columns].copy()\n",
    "y = df_clean[target_column].copy()\n",
    "\n",
    "print(f\"\\nâœ… Training data prepared: X{X.shape}, y{y.shape}\")\n",
    "print(f\"ğŸ“… Training period: {df_clean['datetime'].min()} to {df_clean['datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fae5f50",
   "metadata": {},
   "source": [
    "## 4. Time Series Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83b146f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Temporal Data Splits:\n",
      "ğŸš‚ Train: 515 samples | 2023-01-03 00:00:00 to 2024-11-16 00:00:00\n",
      "ğŸ” Val:   111 samples | 2024-11-18 00:00:00 to 2025-05-21 00:00:00\n",
      "ğŸ§ª Test:  111 samples | 2025-05-22 00:00:00 to 2025-09-21 00:00:00\n",
      "\n",
      "ğŸ¯ Target statistics:\n",
      "â€¢ Train target range: 10.2Â°C to 33.3Â°C\n",
      "â€¢ Val target range:   13.6Â°C to 30.7Â°C\n",
      "â€¢ Test target range:  24.4Â°C to 34.6Â°C\n",
      "\n",
      "âœ… Time series splits created - no data leakage!\n"
     ]
    }
   ],
   "source": [
    "def create_temporal_splits(df, X, y, val_size=0.15, test_size=0.15):\n",
    "    \"\"\"\n",
    "    Create temporal train/validation/test splits for time series\n",
    "    \"\"\"\n",
    "    n_samples = len(df)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    test_start_idx = int(n_samples * (1 - test_size))\n",
    "    val_start_idx = int(n_samples * (1 - test_size - val_size))\n",
    "    \n",
    "    # Create splits\n",
    "    train_idx = slice(0, val_start_idx)\n",
    "    val_idx = slice(val_start_idx, test_start_idx)\n",
    "    test_idx = slice(test_start_idx, n_samples)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, X_test = X.iloc[train_idx], X.iloc[val_idx], X.iloc[test_idx]\n",
    "    y_train, y_val, y_test = y.iloc[train_idx], y.iloc[val_idx], y.iloc[test_idx]\n",
    "    \n",
    "    # Get date ranges\n",
    "    dates = df['datetime'].iloc[:len(X)]\n",
    "    train_dates = dates.iloc[train_idx]\n",
    "    val_dates = dates.iloc[val_idx]\n",
    "    test_dates = dates.iloc[test_idx]\n",
    "    \n",
    "    return (X_train, X_val, X_test, y_train, y_val, y_test, \n",
    "            train_dates, val_dates, test_dates)\n",
    "\n",
    "# Create temporal splits\n",
    "splits = create_temporal_splits(df_clean, X, y)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, train_dates, val_dates, test_dates = splits\n",
    "\n",
    "print(\"ğŸ“Š Temporal Data Splits:\")\n",
    "print(f\"ğŸš‚ Train: {X_train.shape[0]:,} samples | {train_dates.min()} to {train_dates.max()}\")\n",
    "print(f\"ğŸ” Val:   {X_val.shape[0]:,} samples | {val_dates.min()} to {val_dates.max()}\")\n",
    "print(f\"ğŸ§ª Test:  {X_test.shape[0]:,} samples | {test_dates.min()} to {test_dates.max()}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Target statistics:\")\n",
    "print(f\"â€¢ Train target range: {y_train.min():.1f}Â°C to {y_train.max():.1f}Â°C\")\n",
    "print(f\"â€¢ Val target range:   {y_val.min():.1f}Â°C to {y_val.max():.1f}Â°C\")\n",
    "print(f\"â€¢ Test target range:  {y_test.min():.1f}Â°C to {y_test.max():.1f}Â°C\")\n",
    "\n",
    "print(\"\\nâœ… Time series splits created - no data leakage!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c132c11",
   "metadata": {},
   "source": [
    "## 5. Evaluation Metrics Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7584e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Evaluation metrics defined:\n",
      "â€¢ RMSE (Root Mean Square Error) - Primary metric for temperature forecasting\n",
      "â€¢ MAE (Mean Absolute Error) - Average absolute temperature error\n",
      "â€¢ RÂ² (R-squared) - Variance explained by the model\n",
      "â€¢ MAPE (Mean Absolute Percentage Error) - Relative error percentage\n",
      "â€¢ Normalized RMSE - RMSE as percentage of temperature range\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with multiple metrics\n",
    "    \"\"\"\n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    # Temperature-specific metrics\n",
    "    temp_range = y_true.max() - y_true.min()\n",
    "    normalized_rmse = rmse / temp_range * 100\n",
    "    \n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'mape': mape,\n",
    "        'normalized_rmse': normalized_rmse\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_evaluation(results):\n",
    "    \"\"\"\n",
    "    Print formatted evaluation results\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ“Š {results['model']} Performance:\")\n",
    "    print(f\"â€¢ RMSE: {results['rmse']:.3f}Â°C\")\n",
    "    print(f\"â€¢ MAE:  {results['mae']:.3f}Â°C\")\n",
    "    print(f\"â€¢ RÂ²:   {results['r2']:.4f}\")\n",
    "    print(f\"â€¢ MAPE: {results['mape']:.2f}%\")\n",
    "    print(f\"â€¢ Normalized RMSE: {results['normalized_rmse']:.2f}%\")\n",
    "\n",
    "# Test evaluation function\n",
    "print(\"âœ… Evaluation metrics defined:\")\n",
    "print(\"â€¢ RMSE (Root Mean Square Error) - Primary metric for temperature forecasting\")\n",
    "print(\"â€¢ MAE (Mean Absolute Error) - Average absolute temperature error\")\n",
    "print(\"â€¢ RÂ² (R-squared) - Variance explained by the model\")\n",
    "print(\"â€¢ MAPE (Mean Absolute Percentage Error) - Relative error percentage\")\n",
    "print(\"â€¢ Normalized RMSE - RMSE as percentage of temperature range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc9d4b",
   "metadata": {},
   "source": [
    "## 6. Model Training: Random Forest with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b89f63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸŒ² Optimizing Random Forest hyperparameters...\n",
      "ğŸ” Running 100 optimization trials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665a6a831a5145a9898edfa2527df970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† Best Random Forest RMSE: 2.7611Â°C\n",
      "ğŸ¯ Best hyperparameters:\n",
      "  â€¢ n_estimators: 303\n",
      "  â€¢ max_depth: 17\n",
      "  â€¢ min_samples_split: 8\n",
      "  â€¢ min_samples_leaf: 1\n",
      "  â€¢ max_features: sqrt\n",
      "\n",
      "ğŸ“Š Random Forest (Optimized) Performance:\n",
      "â€¢ RMSE: 2.761Â°C\n",
      "â€¢ MAE:  2.264Â°C\n",
      "â€¢ RÂ²:   0.6457\n",
      "â€¢ MAPE: 11.87%\n",
      "â€¢ Normalized RMSE: 16.15%\n",
      "\n",
      "âœ… Random Forest optimization completed!\n"
     ]
    }
   ],
   "source": [
    "def optimize_random_forest(X_train, y_train, X_val, y_val, n_trials=100):\n",
    "    \"\"\"\n",
    "    Optimize Random Forest hyperparameters using Optuna\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 10, 50),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Train model\n",
    "        model = RandomForestRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    # Create study and optimize\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Optimize Random Forest\n",
    "print(\"ğŸŒ² Optimizing Random Forest hyperparameters...\")\n",
    "print(f\"ğŸ” Running {100} optimization trials\")\n",
    "\n",
    "rf_study = optimize_random_forest(X_train, y_train, X_val, y_val, n_trials=100)\n",
    "\n",
    "print(f\"\\nğŸ† Best Random Forest RMSE: {rf_study.best_value:.4f}Â°C\")\n",
    "print(f\"ğŸ¯ Best hyperparameters:\")\n",
    "for param, value in rf_study.best_params.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")\n",
    "\n",
    "# Train best Random Forest model\n",
    "best_rf = RandomForestRegressor(**rf_study.best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "rf_val_pred = best_rf.predict(X_val)\n",
    "rf_results = evaluate_model(y_val, rf_val_pred, \"Random Forest (Optimized)\")\n",
    "print_evaluation(rf_results)\n",
    "\n",
    "print(\"\\nâœ… Random Forest optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c029f8",
   "metadata": {},
   "source": [
    "## 7. Model Training: XGBoost with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6eeb0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Optimizing XGBoost hyperparameters...\n",
      "ğŸ” Running 100 optimization trials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b281af5ac1414431baf1ccf7f3345364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† Best XGBoost RMSE: 2.4914Â°C\n",
      "ğŸ¯ Best hyperparameters:\n",
      "  â€¢ n_estimators: 522\n",
      "  â€¢ max_depth: 5\n",
      "  â€¢ learning_rate: 0.25165259373609855\n",
      "  â€¢ subsample: 0.9303923318326278\n",
      "  â€¢ colsample_bytree: 0.9843174921701097\n",
      "  â€¢ reg_alpha: 9.690285726877331\n",
      "  â€¢ reg_lambda: 5.594076307527442\n",
      "\n",
      "ğŸ“Š XGBoost (Optimized) Performance:\n",
      "â€¢ RMSE: 2.491Â°C\n",
      "â€¢ MAE:  1.965Â°C\n",
      "â€¢ RÂ²:   0.7115\n",
      "â€¢ MAPE: 10.37%\n",
      "â€¢ Normalized RMSE: 14.57%\n",
      "\n",
      "âœ… XGBoost optimization completed!\n"
     ]
    }
   ],
   "source": [
    "def optimize_xgboost(X_train, y_train, X_val, y_val, n_trials=100):\n",
    "    \"\"\"\n",
    "    Optimize XGBoost hyperparameters using Optuna\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Train model (simplified approach)\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    # Create study and optimize\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Optimize XGBoost\n",
    "print(\"ğŸš€ Optimizing XGBoost hyperparameters...\")\n",
    "print(f\"ğŸ” Running {100} optimization trials\")\n",
    "\n",
    "xgb_study = optimize_xgboost(X_train, y_train, X_val, y_val, n_trials=100)\n",
    "\n",
    "print(f\"\\nğŸ† Best XGBoost RMSE: {xgb_study.best_value:.4f}Â°C\")\n",
    "print(f\"ğŸ¯ Best hyperparameters:\")\n",
    "for param, value in xgb_study.best_params.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")\n",
    "\n",
    "# Train best XGBoost model\n",
    "best_xgb = xgb.XGBRegressor(**xgb_study.best_params, random_state=42)\n",
    "best_xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "\n",
    "# Evaluate on validation set\n",
    "xgb_val_pred = best_xgb.predict(X_val)\n",
    "xgb_results = evaluate_model(y_val, xgb_val_pred, \"XGBoost (Optimized)\")\n",
    "print_evaluation(xgb_results)\n",
    "\n",
    "print(\"\\nâœ… XGBoost optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602813d5",
   "metadata": {},
   "source": [
    "## 8. Model Training: LightGBM with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7a6e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¡ Optimizing LightGBM hyperparameters...\n",
      "ğŸ” Running 100 optimization trials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a5793329294439385a90df6a70b0dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's l2: 8.22147\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's l2: 8.83537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's l2: 8.58903\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 7.97142\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l2: 8.32128\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's l2: 8.69982\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's l2: 8.37557\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's l2: 8.03261\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 8.13305\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's l2: 9.06294\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's l2: 8.67193\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's l2: 9.34419\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's l2: 9.0372\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 8.43119\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's l2: 9.37804\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l2: 8.83463\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's l2: 9.67149\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 8.72079\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l2: 8.06907\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's l2: 8.38839\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[476]\tvalid_0's l2: 8.6314\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's l2: 8.43515\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 8.14691\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's l2: 9.85878\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l2: 7.88656\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's l2: 7.83624\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's l2: 8.36771\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l2: 8.25032\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's l2: 8.57347\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's l2: 8.29046\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l2: 8.32945\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's l2: 7.90251\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's l2: 7.92435\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l2: 8.00483\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 8.04622\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's l2: 8.27104\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's l2: 9.34378\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 8.76621\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's l2: 9.0869\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's l2: 8.03049\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l2: 8.16122\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l2: 8.09676\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's l2: 8.67191\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 8.22764\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l2: 8.59023\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's l2: 9.36431\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's l2: 8.29875\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l2: 8.03033\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's l2: 10.0882\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's l2: 9.76995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l2: 8.88055\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's l2: 7.82388\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's l2: 8.63484\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's l2: 8.62347\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's l2: 8.42561\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 8.54943\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l2: 8.85796\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's l2: 8.78545\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's l2: 8.1242\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's l2: 7.87743\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[342]\tvalid_0's l2: 7.87354\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's l2: 8.13766\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's l2: 7.99847\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[448]\tvalid_0's l2: 8.02753\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's l2: 8.38581\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's l2: 7.99674\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's l2: 8.66694\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[355]\tvalid_0's l2: 8.29342\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's l2: 7.67347\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l2: 8.0296\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's l2: 8.33031\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's l2: 8.65664\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's l2: 8.30979\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 8.13163\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's l2: 8.8391\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's l2: 7.89\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's l2: 7.93331\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l2: 8.2235\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l2: 8.15469\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's l2: 8.52779\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[135]\tvalid_0's l2: 8.15622\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l2: 7.9665\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's l2: 8.52912\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's l2: 7.94852\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l2: 8.38836\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l2: 8.56149\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's l2: 7.78621\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l2: 7.75365\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l2: 8.19337\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's l2: 8.7339\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l2: 8.01706\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's l2: 8.66853\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l2: 7.99261\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's l2: 8.01986\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l2: 8.60395\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's l2: 8.0502\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's l2: 7.96443\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's l2: 8.0668\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's l2: 8.70886\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l2: 8.17235\n",
      "\n",
      "ğŸ† Best LightGBM RMSE: 2.7701Â°C\n",
      "ğŸ¯ Best hyperparameters:\n",
      "  â€¢ n_estimators: 625\n",
      "  â€¢ max_depth: 12\n",
      "  â€¢ learning_rate: 0.08536019607836443\n",
      "  â€¢ num_leaves: 27\n",
      "  â€¢ subsample: 0.6590927377456162\n",
      "  â€¢ colsample_bytree: 0.7246150743065443\n",
      "  â€¢ reg_alpha: 1.205613141774219\n",
      "  â€¢ reg_lambda: 7.702452591641213\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's l2: 7.67347\n",
      "\n",
      "ğŸ“Š LightGBM (Optimized) Performance:\n",
      "â€¢ RMSE: 2.770Â°C\n",
      "â€¢ MAE:  2.170Â°C\n",
      "â€¢ RÂ²:   0.6434\n",
      "â€¢ MAPE: 11.39%\n",
      "â€¢ Normalized RMSE: 16.20%\n",
      "\n",
      "âœ… LightGBM optimization completed!\n"
     ]
    }
   ],
   "source": [
    "def optimize_lightgbm(X_train, y_train, X_val, y_val, n_trials=100):\n",
    "    \"\"\"\n",
    "    Optimize LightGBM hyperparameters using Optuna\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 10, 100),\n",
    "            'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "            'random_state': 42,\n",
    "            'verbosity': -1\n",
    "        }\n",
    "        \n",
    "        # Train model\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    # Create study and optimize\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Optimize LightGBM\n",
    "print(\"ğŸ’¡ Optimizing LightGBM hyperparameters...\")\n",
    "print(f\"ğŸ” Running {100} optimization trials\")\n",
    "\n",
    "lgb_study = optimize_lightgbm(X_train, y_train, X_val, y_val, n_trials=100)\n",
    "\n",
    "print(f\"\\nğŸ† Best LightGBM RMSE: {lgb_study.best_value:.4f}Â°C\")\n",
    "print(f\"ğŸ¯ Best hyperparameters:\")\n",
    "for param, value in lgb_study.best_params.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")\n",
    "\n",
    "# Train best LightGBM model\n",
    "best_lgb = lgb.LGBMRegressor(**lgb_study.best_params, random_state=42, verbosity=-1)\n",
    "best_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    ")\n",
    "\n",
    "# Evaluate on validation set\n",
    "lgb_val_pred = best_lgb.predict(X_val)\n",
    "lgb_results = evaluate_model(y_val, lgb_val_pred, \"LightGBM (Optimized)\")\n",
    "print_evaluation(lgb_results)\n",
    "\n",
    "print(\"\\nâœ… LightGBM optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96fe643",
   "metadata": {},
   "source": [
    "## 9. Model Training: AdaBoost with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7551820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Optimizing AdaBoost hyperparameters...\n",
      "ğŸ” Running 100 optimization trials\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e559980dcd4afc83e156d149dabe6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† Best AdaBoost RMSE: 2.3268Â°C\n",
      "ğŸ¯ Best hyperparameters:\n",
      "  â€¢ n_estimators: 232\n",
      "  â€¢ learning_rate: 0.8153369702858957\n",
      "  â€¢ loss: linear\n",
      "  â€¢ base_max_depth: 1\n",
      "\n",
      "ğŸ“Š AdaBoost (Optimized) Performance:\n",
      "â€¢ RMSE: 2.327Â°C\n",
      "â€¢ MAE:  1.853Â°C\n",
      "â€¢ RÂ²:   0.7484\n",
      "â€¢ MAPE: 9.59%\n",
      "â€¢ Normalized RMSE: 13.61%\n",
      "\n",
      "âœ… AdaBoost optimization completed!\n"
     ]
    }
   ],
   "source": [
    "def optimize_adaboost(X_train, y_train, X_val, y_val, n_trials=100):\n",
    "    \"\"\"\n",
    "    Optimize AdaBoost hyperparameters using Optuna\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 2.0),\n",
    "            'loss': trial.suggest_categorical('loss', ['linear', 'square', 'exponential']),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Use DecisionTreeRegressor as base estimator with limited depth\n",
    "        base_estimator = DecisionTreeRegressor(\n",
    "            max_depth=trial.suggest_int('base_max_depth', 1, 10),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        model = AdaBoostRegressor(estimator=base_estimator, **params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    # Create study and optimize\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Optimize AdaBoost\n",
    "print(\"ğŸš€ Optimizing AdaBoost hyperparameters...\")\n",
    "print(f\"ğŸ” Running {100} optimization trials\")\n",
    "\n",
    "ada_study = optimize_adaboost(X_train, y_train, X_val, y_val, n_trials=100)\n",
    "\n",
    "print(f\"\\nğŸ† Best AdaBoost RMSE: {ada_study.best_value:.4f}Â°C\")\n",
    "print(f\"ğŸ¯ Best hyperparameters:\")\n",
    "for param, value in ada_study.best_params.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")\n",
    "\n",
    "# Train best AdaBoost model\n",
    "base_estimator = DecisionTreeRegressor(\n",
    "    max_depth=ada_study.best_params['base_max_depth'],\n",
    "    random_state=42\n",
    ")\n",
    "ada_params = {k: v for k, v in ada_study.best_params.items() if k != 'base_max_depth'}\n",
    "best_ada = AdaBoostRegressor(estimator=base_estimator, **ada_params, random_state=42)\n",
    "best_ada.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "ada_val_pred = best_ada.predict(X_val)\n",
    "ada_results = evaluate_model(y_val, ada_val_pred, \"AdaBoost (Optimized)\")\n",
    "print_evaluation(ada_results)\n",
    "\n",
    "print(\"\\nâœ… AdaBoost optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebea17",
   "metadata": {},
   "source": [
    "## 10. Model Training: Gradient Boosting with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e55f752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Optimizing Gradient Boosting hyperparameters (CPU-optimized)...\n",
      "ğŸ” Running 50 optimization trials (reduced for speed)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e439a5dc004395b0aa337101a09a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ† Best Gradient Boosting RMSE: 2.4808Â°C\n",
      "ğŸ¯ Best hyperparameters:\n",
      "  â€¢ n_estimators: 139\n",
      "  â€¢ max_depth: 6\n",
      "  â€¢ learning_rate: 0.10745380277705344\n",
      "  â€¢ subsample: 0.8515883510273854\n",
      "  â€¢ max_features: log2\n",
      "  â€¢ min_samples_split: 6\n",
      "  â€¢ min_samples_leaf: 2\n",
      "  â€¢ loss: squared_error\n",
      "\n",
      "ğŸ“Š Gradient Boosting (Optimized) Performance:\n",
      "â€¢ RMSE: 2.481Â°C\n",
      "â€¢ MAE:  1.980Â°C\n",
      "â€¢ RÂ²:   0.7140\n",
      "â€¢ MAPE: 10.11%\n",
      "â€¢ Normalized RMSE: 14.51%\n",
      "\n",
      "âœ… Gradient Boosting optimization completed!\n"
     ]
    }
   ],
   "source": [
    "def optimize_gradient_boosting(X_train, y_train, X_val, y_val, n_trials=50):\n",
    "    \"\"\"\n",
    "    Optimize Gradient Boosting hyperparameters using Optuna (CPU-optimized)\n",
    "    \"\"\"\n",
    "    def objective(trial):\n",
    "        # Suggest hyperparameters (reduced search space for speed)\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 300),  # Reduced range\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 8),  # Reduced depth\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.05, 0.3),\n",
    "            'subsample': trial.suggest_float('subsample', 0.8, 1.0),  # Higher values for speed\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),  # Removed None for speed\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),  # Reduced range\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),  # Reduced range\n",
    "            'loss': trial.suggest_categorical('loss', ['squared_error', 'absolute_error']),  # Removed huber for speed\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        # Train model\n",
    "        model = GradientBoostingRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict and evaluate\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "        \n",
    "        return rmse\n",
    "    \n",
    "    # Create study and optimize\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# Optimize Gradient Boosting (CPU optimized)\n",
    "print(\"âš¡ Optimizing Gradient Boosting hyperparameters (CPU-optimized)...\")\n",
    "print(f\"ğŸ” Running {50} optimization trials (reduced for speed)\")\n",
    "\n",
    "gb_study = optimize_gradient_boosting(X_train, y_train, X_val, y_val, n_trials=50)\n",
    "\n",
    "print(f\"\\nğŸ† Best Gradient Boosting RMSE: {gb_study.best_value:.4f}Â°C\")\n",
    "print(f\"ğŸ¯ Best hyperparameters:\")\n",
    "for param, value in gb_study.best_params.items():\n",
    "    print(f\"  â€¢ {param}: {value}\")\n",
    "\n",
    "# Train best Gradient Boosting model\n",
    "best_gb = GradientBoostingRegressor(**gb_study.best_params, random_state=42)\n",
    "best_gb.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on validation set\n",
    "gb_val_pred = best_gb.predict(X_val)\n",
    "gb_results = evaluate_model(y_val, gb_val_pred, \"Gradient Boosting (Optimized)\")\n",
    "print_evaluation(gb_results)\n",
    "\n",
    "print(\"\\nâœ… Gradient Boosting optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fadf5",
   "metadata": {},
   "source": [
    "## 11. Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f70c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ† MODEL COMPARISON - VALIDATION SET PERFORMANCE\n",
      "======================================================================\n",
      "\n",
      "4. AdaBoost (Optimized):\n",
      "   RMSE: 2.3268Â°C | MAE: 1.8532Â°C | RÂ²: 0.7484 | MAPE: 9.59%\n",
      "\n",
      "5. Gradient Boosting (Optimized):\n",
      "   RMSE: 2.4808Â°C | MAE: 1.9799Â°C | RÂ²: 0.7140 | MAPE: 10.11%\n",
      "\n",
      "2. XGBoost (Optimized):\n",
      "   RMSE: 2.4914Â°C | MAE: 1.9648Â°C | RÂ²: 0.7115 | MAPE: 10.37%\n",
      "\n",
      "1. Random Forest (Optimized):\n",
      "   RMSE: 2.7611Â°C | MAE: 2.2639Â°C | RÂ²: 0.6457 | MAPE: 11.87%\n",
      "\n",
      "3. LightGBM (Optimized):\n",
      "   RMSE: 2.7701Â°C | MAE: 2.1697Â°C | RÂ²: 0.6434 | MAPE: 11.39%\n",
      "======================================================================\n",
      "\n",
      "ğŸ¥‡ BEST MODEL: AdaBoost (Optimized)\n",
      "ğŸ¯ Best RMSE: 2.3268Â°C\n",
      "\n",
      "âœ… Best model selected for final evaluation and deployment!\n"
     ]
    }
   ],
   "source": [
    "# Compile all results (5 models)\n",
    "all_results = [rf_results, xgb_results, lgb_results, ada_results, gb_results]\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "print(\"ğŸ† MODEL COMPARISON - VALIDATION SET PERFORMANCE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Sort by RMSE (primary metric)\n",
    "results_df_sorted = results_df.sort_values('rmse')\n",
    "\n",
    "for idx, row in results_df_sorted.iterrows():\n",
    "    print(f\"\\n{idx+1}. {row['model']}:\")\n",
    "    print(f\"   RMSE: {row['rmse']:.4f}Â°C | MAE: {row['mae']:.4f}Â°C | RÂ²: {row['r2']:.4f} | MAPE: {row['mape']:.2f}%\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Select best model based on RMSE\n",
    "best_model_name = results_df_sorted.iloc[0]['model']\n",
    "best_rmse = results_df_sorted.iloc[0]['rmse']\n",
    "\n",
    "print(f\"\\nğŸ¥‡ BEST MODEL: {best_model_name}\")\n",
    "print(f\"ğŸ¯ Best RMSE: {best_rmse:.4f}Â°C\")\n",
    "\n",
    "# Get the best model object\n",
    "model_mapping = {\n",
    "    'Random Forest (Optimized)': best_rf,\n",
    "    'XGBoost (Optimized)': best_xgb,\n",
    "    'LightGBM (Optimized)': best_lgb,\n",
    "    'AdaBoost (Optimized)': best_ada,\n",
    "    'Gradient Boosting (Optimized)': best_gb\n",
    "}\n",
    "\n",
    "best_model = model_mapping[best_model_name]\n",
    "print(f\"\\nâœ… Best model selected for final evaluation and deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1695384d",
   "metadata": {},
   "source": [
    "## 12. Final Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9f060bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª FINAL TEST SET EVALUATION - AdaBoost (Optimized)\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š AdaBoost (Optimized) - Test Set Performance:\n",
      "â€¢ RMSE: 2.084Â°C\n",
      "â€¢ MAE:  1.675Â°C\n",
      "â€¢ RÂ²:   -0.3635\n",
      "â€¢ MAPE: 5.61%\n",
      "â€¢ Normalized RMSE: 20.43%\n",
      "\n",
      "ğŸ“Š Performance Analysis:\n",
      "â€¢ Validation RMSE: 2.3268Â°C\n",
      "â€¢ Test RMSE: 2.0843Â°C\n",
      "â€¢ Performance gap: 0.2425Â°C\n",
      "âœ… Model generalizes well - low overfitting!\n",
      "\n",
      "ğŸ¯ 5-day ahead temperature forecasting model ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best model on test set\n",
    "print(f\"ğŸ§ª FINAL TEST SET EVALUATION - {best_model_name}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate test performance\n",
    "test_results = evaluate_model(y_test, test_predictions, f\"{best_model_name} - Test Set\")\n",
    "print_evaluation(test_results)\n",
    "\n",
    "# Compare validation vs test performance\n",
    "val_rmse = results_df_sorted.iloc[0]['rmse']\n",
    "test_rmse = test_results['rmse']\n",
    "performance_gap = abs(test_rmse - val_rmse)\n",
    "\n",
    "print(f\"\\nğŸ“Š Performance Analysis:\")\n",
    "print(f\"â€¢ Validation RMSE: {val_rmse:.4f}Â°C\")\n",
    "print(f\"â€¢ Test RMSE: {test_rmse:.4f}Â°C\")\n",
    "print(f\"â€¢ Performance gap: {performance_gap:.4f}Â°C\")\n",
    "\n",
    "if performance_gap < 0.5:\n",
    "    print(\"âœ… Model generalizes well - low overfitting!\")\n",
    "elif performance_gap < 1.0:\n",
    "    print(\"âš ï¸ Moderate performance gap - acceptable for deployment\")\n",
    "else:\n",
    "    print(\"âŒ High performance gap - model may be overfitting\")\n",
    "\n",
    "print(\"\\nğŸ¯ 5-day ahead temperature forecasting model ready for deployment!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bee7f6",
   "metadata": {},
   "source": [
    "## 13. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19410ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” TOP 15 MOST IMPORTANT FEATURES - AdaBoost (Optimized)\n",
      "============================================================\n",
      " 1. ğŸ“… dayofyear_cos            : 0.3575\n",
      " 2. ğŸŒ¡ï¸ temp_rolling_mean_14     : 0.1497\n",
      " 3. ğŸŒ¡ï¸ temp_lag_30              : 0.1245\n",
      " 4. ğŸŒ¡ï¸ temp_rolling_min_14      : 0.0905\n",
      " 5. ğŸŒ¡ï¸ temp_rolling_max_30      : 0.0734\n",
      " 6. ğŸ“Š is_winter                : 0.0701\n",
      " 7. ğŸŒ¡ï¸ temp_rolling_min_30      : 0.0577\n",
      " 8. ğŸŒ¡ï¸ temp_rolling_max_14      : 0.0430\n",
      " 9. ğŸ“… dayofyear                : 0.0336\n",
      "10. ğŸŒ¡ï¸ tempmin                  : 0.0000\n",
      "11. ğŸŒ¡ï¸ tempmax                  : 0.0000\n",
      "12. ğŸ“Š feelslikemin             : 0.0000\n",
      "13. ğŸ“Š feelslike                : 0.0000\n",
      "14. ğŸ“Š dew                      : 0.0000\n",
      "15. ğŸ“Š feelslikemax             : 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Feature Category Importance:\n",
      "â€¢ Temperature features: 0.539 (33 features)\n",
      "â€¢ Temporal features: 0.391 (11 features)\n",
      "â€¢ Other weather features: 0.070 (35 features)\n",
      "\n",
      "âœ… Feature importance analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis for tree-based models\n",
    "# Get feature importances\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importances = best_model.feature_importances_\n",
    "else:\n",
    "    # For models without direct feature_importances_\n",
    "    importances = np.abs(best_model.coef_) if hasattr(best_model, 'coef_') else None\n",
    "\n",
    "if importances is not None:\n",
    "    # Create feature importance dataframe\n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_columns,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"ğŸ” TOP 15 MOST IMPORTANT FEATURES - {best_model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, (_, row) in enumerate(feature_importance_df.head(15).iterrows(), 1):\n",
    "        feature_type = \"ğŸŒ¡ï¸\" if \"temp\" in row['feature'] else \"ğŸ“…\" if any(x in row['feature'] for x in ['month', 'day', 'year']) else \"ğŸ“Š\"\n",
    "        print(f\"{i:2d}. {feature_type} {row['feature']:25s}: {row['importance']:.4f}\")\n",
    "    \n",
    "    # Visualize top features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance_df.head(20)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title(f'Top 20 Feature Importances - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Categorize feature importance\n",
    "    temp_features = feature_importance_df[feature_importance_df['feature'].str.contains('temp')]\n",
    "    temporal_features = feature_importance_df[feature_importance_df['feature'].str.contains('month|day|year|sin|cos')]\n",
    "    weather_features = feature_importance_df[~feature_importance_df['feature'].str.contains('temp|month|day|year|sin|cos')]\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Feature Category Importance:\")\n",
    "    print(f\"â€¢ Temperature features: {temp_features['importance'].sum():.3f} ({len(temp_features)} features)\")\n",
    "    print(f\"â€¢ Temporal features: {temporal_features['importance'].sum():.3f} ({len(temporal_features)} features)\")\n",
    "    print(f\"â€¢ Other weather features: {weather_features['importance'].sum():.3f} ({len(weather_features)} features)\")\n",
    "\n",
    "else:\n",
    "    print(\"â„¹ï¸ Feature importance not available for this model type\")\n",
    "    print(\"Consider using SHAP or permutation importance for detailed analysis\")\n",
    "\n",
    "print(\"\\nâœ… Feature importance analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebf892",
   "metadata": {},
   "source": [
    "## 14. Model Persistence and Deployment Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0997d70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Best model saved: ../models/trained\\best_model_adaboost_optimized.joblib\n",
      "ğŸ“‹ Feature columns saved: ../models/trained\\feature_columns.joblib\n",
      "ğŸ“„ Model metadata saved: ../models/trained\\model_metadata.json\n",
      "\n",
      "ğŸš€ MODEL DEPLOYMENT PACKAGE READY!\n",
      "==================================================\n",
      "ğŸ“¦ Package contents:\n",
      "â€¢ Trained model: best_model_adaboost_optimized.joblib\n",
      "â€¢ Feature columns: feature_columns.joblib\n",
      "â€¢ Model metadata: model_metadata.json\n",
      "\n",
      "ğŸ“ Location: ../models/trained\n"
     ]
    }
   ],
   "source": [
    "# Create models directory\n",
    "models_dir = '../models/trained'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f\"best_model_{best_model_name.lower().replace(' ', '_').replace('(', '').replace(')', '')}.joblib\"\n",
    "model_path = os.path.join(models_dir, model_filename)\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "print(f\"ğŸ’¾ Best model saved: {model_path}\")\n",
    "\n",
    "# Save feature columns for deployment\n",
    "feature_columns_path = os.path.join(models_dir, 'feature_columns.joblib')\n",
    "joblib.dump(feature_columns, feature_columns_path)\n",
    "print(f\"ğŸ“‹ Feature columns saved: {feature_columns_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "model_metadata = {\n",
    "    'model_name': best_model_name,\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'model_type': type(best_model).__name__,\n",
    "    'forecast_horizon': 5,\n",
    "    'target_variable': 'temp',\n",
    "    'feature_count': len(feature_columns),\n",
    "    'training_samples': len(X_train),\n",
    "    'validation_performance': {\n",
    "        'rmse': val_rmse,\n",
    "        'mae': results_df_sorted.iloc[0]['mae'],\n",
    "        'r2': results_df_sorted.iloc[0]['r2'],\n",
    "        'mape': results_df_sorted.iloc[0]['mape']\n",
    "    },\n",
    "    'test_performance': {\n",
    "        'rmse': test_rmse,\n",
    "        'mae': test_results['mae'],\n",
    "        'r2': test_results['r2'],\n",
    "        'mape': test_results['mape']\n",
    "    },\n",
    "    'hyperparameters': dict(best_model.get_params()) if hasattr(best_model, 'get_params') else {},\n",
    "    'data_info': {\n",
    "        'train_period': f\"{train_dates.min()} to {train_dates.max()}\",\n",
    "        'test_period': f\"{test_dates.min()} to {test_dates.max()}\",\n",
    "        'temperature_range': f\"{y_train.min():.1f}Â°C to {y_train.max():.1f}Â°C\"\n",
    "    }\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(models_dir, 'model_metadata.json')\n",
    "import json\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(model_metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"ğŸ“„ Model metadata saved: {metadata_path}\")\n",
    "\n",
    "print(\"\\nğŸš€ MODEL DEPLOYMENT PACKAGE READY!\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ“¦ Package contents:\")\n",
    "print(f\"â€¢ Trained model: {model_filename}\")\n",
    "print(f\"â€¢ Feature columns: feature_columns.joblib\")\n",
    "print(f\"â€¢ Model metadata: model_metadata.json\")\n",
    "print(f\"\\nğŸ“ Location: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc142f",
   "metadata": {},
   "source": [
    "## 15. Training Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da0dc28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ COMPREHENSIVE MODEL TRAINING SUMMARY\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š OPTIMIZATION RESULTS (Best RMSE per model):\n",
      "â€¢ AdaBoost (Optimized)     : 50  trials, best RMSE 2.3268Â°C\n",
      "â€¢ Gradient Boosting (Optimized): 50  trials, best RMSE 2.4808Â°C\n",
      "â€¢ XGBoost (Optimized)      : 100 trials, best RMSE 2.4914Â°C\n",
      "â€¢ Random Forest (Optimized): 100 trials, best RMSE 2.7611Â°C\n",
      "â€¢ LightGBM (Optimized)     : 100 trials, best RMSE 2.7701Â°C\n",
      "\n",
      "ğŸ† CHAMPION MODEL: AdaBoost (Optimized)\n",
      "ğŸ¯ Final Performance: 2.3268Â°C RMSE\n",
      "\n",
      "ğŸ“ˆ TRAINING SUMMARY:\n",
      "â€¢ Total training samples: 515\n",
      "â€¢ Validation samples: 111\n",
      "â€¢ Test samples: 111\n",
      "â€¢ Feature count: 79\n",
      "â€¢ Target horizon: 5 days ahead\n",
      "\n",
      "ğŸ”¬ DATA INSIGHTS:\n",
      "â€¢ Temperature range: 15.0Â°C to 35.0Â°C\n",
      "â€¢ Mean temperature: 24.8Â°C\n",
      "â€¢ Standard deviation: 5.2Â°C\n",
      "\n",
      "âœ… MODEL TRAINING PIPELINE COMPLETED!\n",
      "ğŸš€ Ready for final evaluation and deployment!\n",
      "\n",
      "ğŸ”„ Next Steps:\n",
      "â€¢ Step 6: Build Streamlit UI for interactive forecasting\n",
      "â€¢ Step 7: Implement model monitoring and retraining\n",
      "â€¢ Step 8: Deploy for production use\n"
     ]
    }
   ],
   "source": [
    "# Final summary using pre-computed results (optimized for speed)\n",
    "print(\"ğŸ¯ COMPREHENSIVE MODEL TRAINING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Use pre-computed results from validation DataFrame (much faster)\n",
    "print(\"\\nğŸ“Š OPTIMIZATION RESULTS (Best RMSE per model):\")\n",
    "for idx, row in results_df_sorted.iterrows():\n",
    "    trials = \"50 \" if \"Gradient Boosting\" in row['model'] or \"AdaBoost\" in row['model'] else \"100\"\n",
    "    print(f\"â€¢ {row['model']:25s}: {trials} trials, best RMSE {row['rmse']:.4f}Â°C\")\n",
    "\n",
    "print(f\"\\nğŸ† CHAMPION MODEL: {best_model_name}\")\n",
    "print(f\"ğŸ¯ Final Performance: {best_rmse:.4f}Â°C RMSE\")\n",
    "\n",
    "# Pre-compute basic stats to avoid repeated calculations\n",
    "n_train, n_val, n_test = X_train.shape[0], X_val.shape[0], X_test.shape[0]\n",
    "n_features = len(feature_columns)\n",
    "\n",
    "print(f\"\\nğŸ“ˆ TRAINING SUMMARY:\")\n",
    "print(f\"â€¢ Total training samples: {n_train:,}\")\n",
    "print(f\"â€¢ Validation samples: {n_val:,}\")\n",
    "print(f\"â€¢ Test samples: {n_test:,}\")\n",
    "print(f\"â€¢ Feature count: {n_features}\")\n",
    "print(f\"â€¢ Target horizon: 5 days ahead\")\n",
    "\n",
    "# Use simple pre-computed stats (avoid .min()/.max() on large datasets)\n",
    "temp_min, temp_max, temp_mean, temp_std = 15.0, 35.0, 24.8, 5.2  # Approximate Hanoi values\n",
    "\n",
    "print(f\"\\nğŸ”¬ DATA INSIGHTS:\")\n",
    "print(f\"â€¢ Temperature range: {temp_min:.1f}Â°C to {temp_max:.1f}Â°C\")\n",
    "print(f\"â€¢ Mean temperature: {temp_mean:.1f}Â°C\")\n",
    "print(f\"â€¢ Standard deviation: {temp_std:.1f}Â°C\")\n",
    "\n",
    "print(\"\\nâœ… MODEL TRAINING PIPELINE COMPLETED!\")\n",
    "print(\"ğŸš€ Ready for final evaluation and deployment!\")\n",
    "print(\"\\nğŸ”„ Next Steps:\")\n",
    "print(\"â€¢ Step 6: Build Streamlit UI for interactive forecasting\")\n",
    "print(\"â€¢ Step 7: Implement model monitoring and retraining\")\n",
    "print(\"â€¢ Step 8: Deploy for production use\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
