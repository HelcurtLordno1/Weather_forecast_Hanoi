{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fb9517b",
   "metadata": {},
   "source": [
    "# Feature Engineering - Hanoi Weather Forecasting\n",
    "\n",
    "## Step 4: Advanced Feature Engineering for Temperature Forecasting\n",
    "\n",
    "This notebook transforms raw weather data into features suitable for **5-day ahead temperature forecasting**.\n",
    "\n",
    "### üéØ Forecasting Definition:\n",
    "**Goal**: Use daily weather data to predict Hanoi temperature for the **next 5 days**\n",
    "\n",
    "### üöÄ Feature Engineering Objectives:\n",
    "1. **Temporal Features** - Extract time-based patterns (seasonality, trends)\n",
    "2. **Lag Features** - Use historical temperature data (1-7 days back)\n",
    "3. **Rolling Statistics** - Moving averages and variability measures\n",
    "4. **Text Feature Processing** - Transform weather descriptions into numerical features\n",
    "5. **Cyclical Encoding** - Handle seasonal and daily cycles\n",
    "6. **Weather Pattern Features** - Derive meaningful weather indicators\n",
    "7. **Target Engineering** - Create future temperature targets for training\n",
    "\n",
    "### üìä Input ‚Üí Output:\n",
    "Raw 33 features ‚Üí Engineered 100+ features ‚Üí Ready for ML forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b513b02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Feature Engineering Libraries loaded successfully!\n",
      "üéØ Ready to engineer features for 5-day temperature forecasting\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Feature engineering libraries\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette('plasma')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚öôÔ∏è Feature Engineering Libraries loaded successfully!\")\n",
    "print(\"üéØ Ready to engineer features for 5-day temperature forecasting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f675b647",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6bae403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Base Dataset Shape: (3660, 33)\n",
      "üìÖ Date Range: 2015-09-20 00:00:00 to 2025-09-26 00:00:00\n",
      "üå°Ô∏è Target (temp) Range: 7.0¬∞C to 35.5¬∞C\n",
      "\n",
      "‚úÖ Data loaded and sorted chronologically for time series feature engineering\n"
     ]
    }
   ],
   "source": [
    "# Load the processed dataset\n",
    "data_path = '../data/raw/Hanoi-Daily-10-years.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert datetime and sort by date\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "print(f\"üìã Base Dataset Shape: {df.shape}\")\n",
    "print(f\"üìÖ Date Range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "print(f\"üå°Ô∏è Target (temp) Range: {df['temp'].min():.1f}¬∞C to {df['temp'].max():.1f}¬∞C\")\n",
    "\n",
    "# Create feature engineering dataset\n",
    "df_features = df.copy()\n",
    "\n",
    "print(\"\\n‚úÖ Data loaded and sorted chronologically for time series feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09751ad0",
   "metadata": {},
   "source": [
    "## 2. Temporal Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83cc657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÖ Temporal Features Created:\n",
      "‚Ä¢ year\n",
      "‚Ä¢ month\n",
      "‚Ä¢ day\n",
      "‚Ä¢ dayofweek\n",
      "‚Ä¢ dayofyear\n",
      "‚Ä¢ week\n",
      "‚Ä¢ quarter\n",
      "‚Ä¢ month_sin\n",
      "‚Ä¢ month_cos\n",
      "‚Ä¢ dayofyear_sin\n",
      "‚Ä¢ dayofyear_cos\n",
      "‚Ä¢ dayofweek_sin\n",
      "‚Ä¢ dayofweek_cos\n",
      "‚Ä¢ season\n",
      "‚Ä¢ is_winter\n",
      "‚Ä¢ is_spring\n",
      "‚Ä¢ is_summer\n",
      "‚Ä¢ is_autumn\n",
      "‚Ä¢ days_since_start\n",
      "‚Ä¢ years_since_start\n",
      "\n",
      "‚úÖ Added 20 temporal features\n"
     ]
    }
   ],
   "source": [
    "def create_temporal_features(df):\n",
    "    \"\"\"\n",
    "    Create comprehensive temporal features from datetime\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Basic time components\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['dayofweek'] = df['datetime'].dt.dayofweek  # 0=Monday\n",
    "    df['dayofyear'] = df['datetime'].dt.dayofyear\n",
    "    df['week'] = df['datetime'].dt.isocalendar().week\n",
    "    df['quarter'] = df['datetime'].dt.quarter\n",
    "    \n",
    "    # Cyclical encoding for periodic features\n",
    "    # Month (12-month cycle)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    \n",
    "    # Day of year (365-day cycle)\n",
    "    df['dayofyear_sin'] = np.sin(2 * np.pi * df['dayofyear'] / 365)\n",
    "    df['dayofyear_cos'] = np.cos(2 * np.pi * df['dayofyear'] / 365)\n",
    "    \n",
    "    # Day of week (7-day cycle)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    # Season indicators\n",
    "    def get_season(month):\n",
    "        if month in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        else:\n",
    "            return 'autumn'\n",
    "    \n",
    "    df['season'] = df['month'].apply(get_season)\n",
    "    \n",
    "    # Binary season indicators\n",
    "    df['is_winter'] = (df['season'] == 'winter').astype(int)\n",
    "    df['is_spring'] = (df['season'] == 'spring').astype(int)\n",
    "    df['is_summer'] = (df['season'] == 'summer').astype(int)\n",
    "    df['is_autumn'] = (df['season'] == 'autumn').astype(int)\n",
    "    \n",
    "    # Time trends\n",
    "    df['days_since_start'] = (df['datetime'] - df['datetime'].min()).dt.days\n",
    "    df['years_since_start'] = df['days_since_start'] / 365.25\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply temporal feature engineering\n",
    "df_features = create_temporal_features(df_features)\n",
    "\n",
    "print(\"üìÖ Temporal Features Created:\")\n",
    "temporal_cols = ['year', 'month', 'day', 'dayofweek', 'dayofyear', 'week', 'quarter',\n",
    "                'month_sin', 'month_cos', 'dayofyear_sin', 'dayofyear_cos',\n",
    "                'dayofweek_sin', 'dayofweek_cos', 'season', 'is_winter', 'is_spring',\n",
    "                'is_summer', 'is_autumn', 'days_since_start', 'years_since_start']\n",
    "\n",
    "for col in temporal_cols:\n",
    "    if col in df_features.columns:\n",
    "        print(f\"‚Ä¢ {col}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Added {len([c for c in temporal_cols if c in df_features.columns])} temporal features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9f2d3",
   "metadata": {},
   "source": [
    "## 3. Lag Features for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9040c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Created 36 lag and difference features:\n",
      "\n",
      "Temperature lags:\n",
      "['temp_lag_1', 'temp_lag_2', 'temp_lag_3', 'temp_lag_4', 'temp_lag_5', 'temp_lag_6', 'temp_lag_7', 'temp_lag_14', 'temp_lag_30']\n",
      "\n",
      "Temperature differences:\n",
      "['temp_diff_1d', 'temp_diff_2d', 'temp_diff_7d']\n",
      "\n",
      "‚úÖ Total lag-based features: 36\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, target_col='temp', lag_days=[1, 2, 3, 4, 5, 6, 7, 14, 30]):\n",
    "    \"\"\"\n",
    "    Create lag features for temperature forecasting\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Temperature lag features\n",
    "    for lag in lag_days:\n",
    "        df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)\n",
    "        \n",
    "    # Additional weather feature lags (shorter lags)\n",
    "    weather_features = ['tempmax', 'tempmin', 'humidity', 'precip', 'windspeed', 'sealevelpressure']\n",
    "    short_lags = [1, 2, 3, 7]\n",
    "    \n",
    "    for feature in weather_features:\n",
    "        if feature in df.columns:\n",
    "            for lag in short_lags:\n",
    "                df[f'{feature}_lag_{lag}'] = df[feature].shift(lag)\n",
    "    \n",
    "    # Temperature differences (day-to-day changes)\n",
    "    df['temp_diff_1d'] = df[target_col] - df[target_col].shift(1)\n",
    "    df['temp_diff_2d'] = df[target_col] - df[target_col].shift(2)\n",
    "    df['temp_diff_7d'] = df[target_col] - df[target_col].shift(7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply lag feature engineering\n",
    "df_features = create_lag_features(df_features)\n",
    "\n",
    "# Count lag features\n",
    "lag_features = [col for col in df_features.columns if '_lag_' in col or 'temp_diff_' in col]\n",
    "print(f\"üîÑ Created {len(lag_features)} lag and difference features:\")\n",
    "print(\"\\nTemperature lags:\")\n",
    "temp_lags = [col for col in lag_features if col.startswith('temp_lag_')]\n",
    "print(temp_lags)\n",
    "\n",
    "print(\"\\nTemperature differences:\")\n",
    "temp_diffs = [col for col in lag_features if 'temp_diff_' in col]\n",
    "print(temp_diffs)\n",
    "\n",
    "print(f\"\\n‚úÖ Total lag-based features: {len(lag_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f45ec5b",
   "metadata": {},
   "source": [
    "## 4. Rolling Window Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0363d6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Created 51 rolling statistical features\n",
      "\n",
      "Example temperature rolling features:\n",
      "‚Ä¢ temp_rolling_mean_3\n",
      "‚Ä¢ temp_rolling_std_3\n",
      "‚Ä¢ temp_rolling_min_3\n",
      "‚Ä¢ temp_rolling_max_3\n",
      "‚Ä¢ temp_rolling_range_3\n",
      "‚Ä¢ temp_position_in_range_3\n",
      "‚Ä¢ temp_rolling_mean_7\n",
      "‚Ä¢ temp_rolling_std_7\n",
      "‚Ä¢ temp_rolling_min_7\n",
      "‚Ä¢ temp_rolling_max_7\n",
      "\n",
      "‚úÖ Total rolling features: 51\n"
     ]
    }
   ],
   "source": [
    "def create_rolling_features(df, target_col='temp', windows=[3, 7, 14, 30]):\n",
    "    \"\"\"\n",
    "    Create rolling window statistical features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Rolling statistics for temperature\n",
    "    for window in windows:\n",
    "        # Basic statistics\n",
    "        df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window=window).mean()\n",
    "        df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window=window).std()\n",
    "        df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(window=window).min()\n",
    "        df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(window=window).max()\n",
    "        \n",
    "        # Range and variability\n",
    "        df[f'{target_col}_rolling_range_{window}'] = (df[f'{target_col}_rolling_max_{window}'] - \n",
    "                                                     df[f'{target_col}_rolling_min_{window}'])\n",
    "        \n",
    "        # Relative position in range\n",
    "        df[f'{target_col}_position_in_range_{window}'] = ((df[target_col] - df[f'{target_col}_rolling_min_{window}']) /\n",
    "                                                         (df[f'{target_col}_rolling_range_{window}'] + 1e-8))\n",
    "    \n",
    "    # Rolling statistics for other key features\n",
    "    other_features = ['humidity', 'precip', 'windspeed', 'solarradiation']\n",
    "    short_windows = [3, 7, 14]\n",
    "    \n",
    "    for feature in other_features:\n",
    "        if feature in df.columns:\n",
    "            for window in short_windows:\n",
    "                df[f'{feature}_rolling_mean_{window}'] = df[feature].rolling(window=window).mean()\n",
    "                df[f'{feature}_rolling_std_{window}'] = df[feature].rolling(window=window).std()\n",
    "    \n",
    "    # Exponential moving averages\n",
    "    df[f'{target_col}_ema_3'] = df[target_col].ewm(span=3).mean()\n",
    "    df[f'{target_col}_ema_7'] = df[target_col].ewm(span=7).mean()\n",
    "    df[f'{target_col}_ema_30'] = df[target_col].ewm(span=30).mean()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply rolling feature engineering\n",
    "df_features = create_rolling_features(df_features)\n",
    "\n",
    "# Count rolling features\n",
    "rolling_features = [col for col in df_features.columns if ('_rolling_' in col or '_ema_' in col or '_position_' in col)]\n",
    "print(f\"üìä Created {len(rolling_features)} rolling statistical features\")\n",
    "\n",
    "# Display some examples\n",
    "temp_rolling = [col for col in rolling_features if col.startswith('temp_')][:10]\n",
    "print(f\"\\nExample temperature rolling features:\")\n",
    "for feat in temp_rolling:\n",
    "    print(f\"‚Ä¢ {feat}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total rolling features: {len(rolling_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397d4956",
   "metadata": {},
   "source": [
    "## 5. Text Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ad1c203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Created 24 text-derived features:\n",
      "\n",
      "Weather pattern indicators:\n",
      "['has_rain', 'has_cloud', 'has_clear', 'has_fog', 'has_storm', 'has_wind']\n",
      "\n",
      "Condition categories:\n",
      "['condition_rain_partially_cloudy', 'condition_partially_cloudy', 'condition_rain_overcast', 'condition_clear', 'condition_overcast']\n",
      "\n",
      "‚úÖ Total text-derived features: 24\n"
     ]
    }
   ],
   "source": [
    "def create_text_features(df):\n",
    "    \"\"\"\n",
    "    Transform text features (conditions, description) into numerical features\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Weather Conditions Processing\n",
    "    if 'conditions' in df.columns:\n",
    "        # Clean and standardize conditions\n",
    "        df['conditions_clean'] = df['conditions'].str.lower().str.strip()\n",
    "        \n",
    "        # Extract key weather patterns\n",
    "        df['has_rain'] = df['conditions_clean'].str.contains('rain', na=False).astype(int)\n",
    "        df['has_cloud'] = df['conditions_clean'].str.contains('cloud|overcast', na=False).astype(int)\n",
    "        df['has_clear'] = df['conditions_clean'].str.contains('clear|sunny', na=False).astype(int)\n",
    "        df['has_fog'] = df['conditions_clean'].str.contains('fog|mist', na=False).astype(int)\n",
    "        df['has_storm'] = df['conditions_clean'].str.contains('storm|thunder', na=False).astype(int)\n",
    "        df['has_wind'] = df['conditions_clean'].str.contains('wind', na=False).astype(int)\n",
    "        \n",
    "        # Count weather condition words\n",
    "        df['conditions_word_count'] = df['conditions'].str.split().str.len().fillna(0)\n",
    "        \n",
    "        # One-hot encode most common conditions\n",
    "        top_conditions = df['conditions_clean'].value_counts().head(10).index\n",
    "        for condition in top_conditions:\n",
    "            df[f'condition_{condition.replace(\" \", \"_\").replace(\",\", \"\")}'] = (\n",
    "                df['conditions_clean'] == condition\n",
    "            ).astype(int)\n",
    "    \n",
    "    # 2. Description Processing\n",
    "    if 'description' in df.columns:\n",
    "        # Clean descriptions\n",
    "        df['description_clean'] = df['description'].str.lower().str.strip()\n",
    "        \n",
    "        # Description length and complexity\n",
    "        df['description_length'] = df['description'].str.len().fillna(0)\n",
    "        df['description_word_count'] = df['description'].str.split().str.len().fillna(0)\n",
    "        \n",
    "        # Extract sentiment (positive/negative weather descriptions)\n",
    "        def get_weather_sentiment(text):\n",
    "            if pd.isna(text):\n",
    "                return 0\n",
    "            positive_words = ['clear', 'sunny', 'bright', 'pleasant', 'mild']\n",
    "            negative_words = ['storm', 'heavy', 'severe', 'harsh', 'extreme']\n",
    "            \n",
    "            text_lower = text.lower()\n",
    "            pos_count = sum(1 for word in positive_words if word in text_lower)\n",
    "            neg_count = sum(1 for word in negative_words if word in text_lower)\n",
    "            \n",
    "            return pos_count - neg_count\n",
    "        \n",
    "        df['description_sentiment'] = df['description'].apply(get_weather_sentiment)\n",
    "        \n",
    "        # Extract specific weather events from description\n",
    "        df['desc_has_rain'] = df['description_clean'].str.contains('rain', na=False).astype(int)\n",
    "        df['desc_has_cloud'] = df['description_clean'].str.contains('cloud', na=False).astype(int)\n",
    "        df['desc_has_sun'] = df['description_clean'].str.contains('sun|bright', na=False).astype(int)\n",
    "    \n",
    "    # 3. Icon feature processing\n",
    "    if 'icon' in df.columns:\n",
    "        # Label encode icons\n",
    "        le_icon = LabelEncoder()\n",
    "        df['icon_encoded'] = le_icon.fit_transform(df['icon'].fillna('unknown'))\n",
    "        \n",
    "        # One-hot encode most common icons\n",
    "        top_icons = df['icon'].value_counts().head(8).index\n",
    "        for icon in top_icons:\n",
    "            df[f'icon_{icon}'] = (df['icon'] == icon).astype(int)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply text feature engineering\n",
    "df_features = create_text_features(df_features)\n",
    "\n",
    "# Count text-derived features\n",
    "text_features = [col for col in df_features.columns if any(x in col for x in \n",
    "                ['has_', 'condition_', 'desc_', 'icon_', 'sentiment', 'word_count', 'length'])]\n",
    "\n",
    "print(f\"üìù Created {len(text_features)} text-derived features:\")\n",
    "print(\"\\nWeather pattern indicators:\")\n",
    "pattern_features = [col for col in text_features if col.startswith('has_')]\n",
    "print(pattern_features)\n",
    "\n",
    "print(\"\\nCondition categories:\")\n",
    "condition_features = [col for col in text_features if col.startswith('condition_')][:5]\n",
    "print(condition_features)\n",
    "\n",
    "print(f\"\\n‚úÖ Total text-derived features: {len(text_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41423811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total final features: 131\n",
      "‚úÖ Total final features: 131\n",
      "\n",
      "Final feature columns:\n",
      "‚Ä¢ year\n",
      "‚Ä¢ month\n",
      "‚Ä¢ day\n",
      "‚Ä¢ dayofweek\n",
      "‚Ä¢ dayofyear\n",
      "‚Ä¢ week\n",
      "‚Ä¢ quarter\n",
      "‚Ä¢ month_sin\n",
      "‚Ä¢ month_cos\n",
      "‚Ä¢ dayofyear_sin\n",
      "‚Ä¢ dayofyear_cos\n",
      "‚Ä¢ dayofweek_sin\n",
      "‚Ä¢ dayofweek_cos\n",
      "‚Ä¢ season\n",
      "‚Ä¢ is_winter\n",
      "‚Ä¢ is_spring\n",
      "‚Ä¢ is_summer\n",
      "‚Ä¢ is_autumn\n",
      "‚Ä¢ days_since_start\n",
      "‚Ä¢ years_since_start\n",
      "‚Ä¢ temp_lag_1\n",
      "‚Ä¢ temp_lag_2\n",
      "‚Ä¢ temp_lag_3\n",
      "‚Ä¢ temp_lag_4\n",
      "‚Ä¢ temp_lag_5\n",
      "‚Ä¢ temp_lag_6\n",
      "‚Ä¢ temp_lag_7\n",
      "‚Ä¢ temp_lag_14\n",
      "‚Ä¢ temp_lag_30\n",
      "‚Ä¢ tempmax_lag_1\n",
      "‚Ä¢ tempmax_lag_2\n",
      "‚Ä¢ tempmax_lag_3\n",
      "‚Ä¢ tempmax_lag_7\n",
      "‚Ä¢ tempmin_lag_1\n",
      "‚Ä¢ tempmin_lag_2\n",
      "‚Ä¢ tempmin_lag_3\n",
      "‚Ä¢ tempmin_lag_7\n",
      "‚Ä¢ humidity_lag_1\n",
      "‚Ä¢ humidity_lag_2\n",
      "‚Ä¢ humidity_lag_3\n",
      "‚Ä¢ humidity_lag_7\n",
      "‚Ä¢ precip_lag_1\n",
      "‚Ä¢ precip_lag_2\n",
      "‚Ä¢ precip_lag_3\n",
      "‚Ä¢ precip_lag_7\n",
      "‚Ä¢ windspeed_lag_1\n",
      "‚Ä¢ windspeed_lag_2\n",
      "‚Ä¢ windspeed_lag_3\n",
      "‚Ä¢ windspeed_lag_7\n",
      "‚Ä¢ sealevelpressure_lag_1\n",
      "‚Ä¢ sealevelpressure_lag_2\n",
      "‚Ä¢ sealevelpressure_lag_3\n",
      "‚Ä¢ sealevelpressure_lag_7\n",
      "‚Ä¢ temp_diff_1d\n",
      "‚Ä¢ temp_diff_2d\n",
      "‚Ä¢ temp_diff_7d\n",
      "‚Ä¢ temp_rolling_mean_3\n",
      "‚Ä¢ temp_rolling_std_3\n",
      "‚Ä¢ temp_rolling_min_3\n",
      "‚Ä¢ temp_rolling_max_3\n",
      "‚Ä¢ temp_rolling_range_3\n",
      "‚Ä¢ temp_position_in_range_3\n",
      "‚Ä¢ temp_rolling_mean_7\n",
      "‚Ä¢ temp_rolling_std_7\n",
      "‚Ä¢ temp_rolling_min_7\n",
      "‚Ä¢ temp_rolling_max_7\n",
      "‚Ä¢ temp_rolling_range_7\n",
      "‚Ä¢ temp_position_in_range_7\n",
      "‚Ä¢ temp_rolling_mean_14\n",
      "‚Ä¢ temp_rolling_std_14\n",
      "‚Ä¢ temp_rolling_min_14\n",
      "‚Ä¢ temp_rolling_max_14\n",
      "‚Ä¢ temp_rolling_range_14\n",
      "‚Ä¢ temp_position_in_range_14\n",
      "‚Ä¢ temp_rolling_mean_30\n",
      "‚Ä¢ temp_rolling_std_30\n",
      "‚Ä¢ temp_rolling_min_30\n",
      "‚Ä¢ temp_rolling_max_30\n",
      "‚Ä¢ temp_rolling_range_30\n",
      "‚Ä¢ temp_position_in_range_30\n",
      "‚Ä¢ humidity_rolling_mean_3\n",
      "‚Ä¢ humidity_rolling_std_3\n",
      "‚Ä¢ humidity_rolling_mean_7\n",
      "‚Ä¢ humidity_rolling_std_7\n",
      "‚Ä¢ humidity_rolling_mean_14\n",
      "‚Ä¢ humidity_rolling_std_14\n",
      "‚Ä¢ precip_rolling_mean_3\n",
      "‚Ä¢ precip_rolling_std_3\n",
      "‚Ä¢ precip_rolling_mean_7\n",
      "‚Ä¢ precip_rolling_std_7\n",
      "‚Ä¢ precip_rolling_mean_14\n",
      "‚Ä¢ precip_rolling_std_14\n",
      "‚Ä¢ windspeed_rolling_mean_3\n",
      "‚Ä¢ windspeed_rolling_std_3\n",
      "‚Ä¢ windspeed_rolling_mean_7\n",
      "‚Ä¢ windspeed_rolling_std_7\n",
      "‚Ä¢ windspeed_rolling_mean_14\n",
      "‚Ä¢ windspeed_rolling_std_14\n",
      "‚Ä¢ solarradiation_rolling_mean_3\n",
      "‚Ä¢ solarradiation_rolling_std_3\n",
      "‚Ä¢ solarradiation_rolling_mean_7\n",
      "‚Ä¢ solarradiation_rolling_std_7\n",
      "‚Ä¢ solarradiation_rolling_mean_14\n",
      "‚Ä¢ solarradiation_rolling_std_14\n",
      "‚Ä¢ temp_ema_3\n",
      "‚Ä¢ temp_ema_7\n",
      "‚Ä¢ temp_ema_30\n",
      "‚Ä¢ has_rain\n",
      "‚Ä¢ has_cloud\n",
      "‚Ä¢ has_clear\n",
      "‚Ä¢ has_fog\n",
      "‚Ä¢ has_storm\n",
      "‚Ä¢ has_wind\n",
      "‚Ä¢ conditions_word_count\n",
      "‚Ä¢ condition_rain_partially_cloudy\n",
      "‚Ä¢ condition_partially_cloudy\n",
      "‚Ä¢ condition_rain_overcast\n",
      "‚Ä¢ condition_clear\n",
      "‚Ä¢ condition_overcast\n",
      "‚Ä¢ condition_rain\n",
      "‚Ä¢ description_length\n",
      "‚Ä¢ description_word_count\n",
      "‚Ä¢ description_sentiment\n",
      "‚Ä¢ desc_has_rain\n",
      "‚Ä¢ desc_has_cloud\n",
      "‚Ä¢ desc_has_sun\n",
      "‚Ä¢ icon_encoded\n",
      "‚Ä¢ icon_rain\n",
      "‚Ä¢ icon_partly-cloudy-day\n",
      "‚Ä¢ icon_clear-day\n",
      "‚Ä¢ icon_cloudy\n",
      "‚úÖ Total final features: 131\n"
     ]
    }
   ],
   "source": [
    "final_feature_cols = temporal_cols + lag_features + rolling_features + text_features\n",
    "final_feature_cols = [col for col in final_feature_cols if col in df_features.columns]\n",
    "print(f\"‚úÖ Total final features: {len(final_feature_cols)}\")\n",
    "l_feature_cols = temporal_cols + lag_features + rolling_features + text_features\n",
    "final_feature_cols = [col for col in final_feature_cols if col in df_features.columns]\n",
    "print(f\"‚úÖ Total final features: {len(final_feature_cols)}\")\n",
    "\n",
    "#print all feature names\n",
    "print(\"\\nFinal feature columns:\")   \n",
    "for col in final_feature_cols:\n",
    "    print(f\"‚Ä¢ {col}\")\n",
    "final_feature_cols = [col for col in final_feature_cols if col in df_features.columns]\n",
    "print(f\"‚úÖ Total final features: {len(final_feature_cols)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
